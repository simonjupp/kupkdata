{\rtf1\ansi\ansicpg1252\cocoartf1038\cocoasubrtf350
{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
\paperw11900\paperh16840\margl1440\margr1440\vieww9000\viewh8400\viewkind0
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\ql\qnatural\pardirnatural

\f0\fs24 \cf0 \ul \ulc0 Perl scripts\
\ulnone \
Entrez gene to RDF.\
\
gene_info_2_rdf.pl\
\
You need to get data from the NCBI ftp server. You can see the filenames in the perl script. All_Mammalian.gene_info is the basic info about mammalian genes. Then we need to connect these to uniprot ids using the gene_refseq_uniprotkb_collab and gene2accession files also available from the NCBI ftp.\
\
{\field{\*\fldinst{HYPERLINK "ftp://ftp.ncbi.nih.gov/gene/"}}{\fldrslt Download/FTP}}\
\
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\ql\qnatural\pardirnatural
\cf0 \ul \ulc0 GOA\ulnone \
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\ql\qnatural\pardirnatural
\cf0 \
Once this has run you have already generated ids for the uniprot proteins, but we need additional information, like name, description and most importantly gene ontology annotations. I am cheating a little here but I simply pass the Gene Ontology Annotation (GOA) files from uniprot, these contain enough relevant information for me to describe the proteins. \
\
The perl scrip it goa_2_unprot.pl. You need to get the gene associations files from uniprot, you can see in the script how they are named. There is one for each species. The mouse is a special case because MGI manage the proteins and GOA so you need an additional mapping file to map MGI accessions to uniprot accessions. I'm not sure if you have these files, but you can get them from the MGI website. \
\
http://www.ebi.ac.uk/GOA/uniprot_release.html\
\
ftp://ftp.informatics.jax.org/pub/reports/index.html\
\
\ul miRNA\
\ulnone \
So genes and proteins are the two most important bits of background knowledge. Next is the miRNA, this is a bit more complicated\'85 I get the target data from microCosm, I map the miRNA ids to the MirBase identifiers. The targets are represented using ensemble transcripts so I have to use the BioMart service, via Taverna to get the appropriate gene ids from the ensembl transcript. Finally I have a script that generates the RDF. I need to collect all these files to gather so I will take care of this and send you everything once I have worked it all out again!\
\
\ul KEGG and HMDB\ulnone \
\
So far I have not been putting KEGG and HMDB into the KUPKB, but I do have versions of them in RDF. Both are generated via two simple perl scripts. Now I haven't shared these yet as I need to check the RDF generated, I believe there are some issues with it that I need to fix. It was all a long time ago so I can't quite remember now so I will get back to you on these. \
\
That is the end of the perl bit and that covers the basic background knowledge. \
\
The next bit is the Java code for parsing the experiment spreadsheets. I have attached a tar ball of my source and lib folders. This is a collection of Java programs that do various kup related stuff. \
\
In the src folder you have:\
\
euregene: this is a special set of files for converting the euregen database into RDF. eueregen is dead now so we don't need to do this for every build. There is a euregene.owl file in the dropbox that can be considered final. \
\
oldscripts: These are old/junk pieces of code that no longer have any relevance. \
\
Ontogrator: Again, this was a project we started, but has since been dropped so it can be ignored / deleted. \
\
\ul kupkb_experiments: This is the code for parsing the spreadsheets and generating the RDF. \
\ulnone \
test.java is quite useful, you can just point it at a spreadsheets and it should generate the owl version. \
\
AllFileGenerator.java is the one I run to do all the spreadsheets in the dropbox folder. \
\
The rest are utility classes that do the work\'85 most of this was written in less than a week when Julie visited Manchester. It ain't pretty but we didn't have time on our side. Like most of this code, would be great to spend some time refactoring, but if it ain't broke I guess there is no need to fix!\
\
One thing to note about the spreadsheet parsers is that it relies on bridge-db. I'm not sure if you have used bridge-db before, but it is fairly simple to set up and it provides a mapping service for gene/protein names to various identifiers and is very handy. It means we can let users submit spreadsheets with just gene names in them and we try and guess the identifier using bridge-db. \
\
\ul package uk.ac.man.ac.uk.kupkb.data:\ulnone  Ignore everything in here, I began writing an API for the KUPKB, but I ported most of this code over to the kupkbweb project.\
\
And last but not least\'85 KUPKB_builder: This is the package that loads all the generated rdf files into the kupkb. I have a file called files_to_load, this contains the path on my machine to all the rdf/owl files that need loading. LoadFiles.java reads these files and puts them in a sesame repository, you can do it over http, but I find it is much faster and more stable to work with the repository files directly. In fact that is how it is set up now. When you do this you can't have the apache service running and connected to the same repository at the same time. This is why it best to have a development sesame sever where you build the kupkb, and then when it is done you just move the repository to the live server.\
\
So that is mostly it! You now have the source, and the lib folder. The only thing you need to get yourself is bridge db installed and set up on your machine.\ul \
\
}